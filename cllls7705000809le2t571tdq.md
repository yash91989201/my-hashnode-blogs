---
title: "üë®‚Äçüè´ Introduction to Kubernetes: an awesome container orchestration tool"
seoTitle: "üë®‚Äçüè´ Introduction to Kubernetes‚öôÔ∏è"
datePublished: Tue Aug 22 2023 04:03:49 GMT+0000 (Coordinated Universal Time)
cuid: cllls7705000809le2t571tdq
slug: introduction-to-kubernetes-an-awesome-container-orchestration-tool
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1692676763631/f8a1199a-e677-496e-b47e-c09075e5b2e0.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1692677003760/e60e6ca6-5d59-42e0-a811-f09865725183.png
tags: kubernetes, kubernetes-setup, kubernetes-architecture, 90daysofdevops, trainwithshubham

---

## üìç Introduction:

Hey there, enthusiastic readers! Get ready for an incredible journey as we dive into Kubernetes, a fantastic container orchestration tool that empowers us to manage multiple containers like a pro! In this blog, we'll be exploring the ins and outs of Kubernetes and it's components!!! üéâüöÄ

## ‚úîÔ∏è Why do we need container orchestration?ü§î

Container orchestration is heavily required in situations where we are running our application in a microservices architecture.

Here are some issues that we will face if we only use containers for serving our application:

* When our application experiences a high volume of users, it needs multiple containers to manage the load. As the number of users increases, we must also increase the number of containers so that our system can handle the load easily. Conversely, if the number of users suddenly decreases, we need to reduce the number of containers to avoid unnecessary overutilization of resources. All these tasks would have to be performed manually.
    
* To introduce a new feature for our application, we must take down our containers, implement the changes, and then restart them. This process results in downtime, which can lead to a poor user experience.
    
* In situations where a newly added feature does not function as expected, we must take down the containers and revert our application to the previous version to guarantee that the application runs smoothly.
    
* Whenever our containers malfunction, we must manually inspect them for errors and bring them back online to ensure proper operation.
    

After reading about the above-mentioned issues, you must have realized that there is a significant amount of manual work required to ensure that our containers run properly. Now, considering these issues, imagine a situation where we need to manage not just a couple, but thousands of containers for our application. In such a scenario, managing the containers manually would become nearly impossible.

To tackle these issues we use the most popular container orchestration tool known as Kubernetes or k8s.

## ‚úîÔ∏è How Kubernetes helps in container orchestration?ü´¥

Here are some of the features of Kubernetes which make it more than a container orchestration tool.

1. **Auto Scaling:** It can automatically add or remove containers according to the increasing or decreasing number of users of our application. Kubernetes is fully capable of performing vertical and horizontal scaling.
    
2. **Auto Healing:** Whenever a container does not work properly it automatically detects it and replaces the malfunctioning container with a new one ensuring that the application performance is never affected.
    
3. **Load balancing:** It evaluates the load on our systems and evenly distributes it among them, ensuring that our application runs smoothly without any lag.
    
4. **Fault tolerance:** Kubernetes also ensures that our application is fault-tolerant, meaning that our containers remain fully operational and maintain zero downtime.
    
5. **Rolling updates:** If we want to update our application in a way that prevents users from experiencing any downtime. Whenever we need to update our application, Kubernetes selects a specific number of containers, determined by the window size, stops them to update with the new version, and then brings them back online, this process is done until all the containers are running the latest version of our application.
    
6. **Rollback:** When our application fails to run as expected or encounters errors, Kubernetes can assist us in restoring our application to its previous functional state by rolling back to the prior working version.
    
7. **Health monitoring of containers:** It continuously monitors the state of all the containers so that it can perform auto-healing.
    
8. **Platform independent:** Kubernetes is platform-independent, meaning that any machine can be used as a worker node to run our containers, whether it's bare metal, a virtual machine, an on-premises server or a cloud server.
    

After learning that Kubernetes offers this many features we can say that it is much more than a container orchestration tool.

## ‚úîÔ∏è The architecture of Kubernetes.üèôÔ∏è

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1692675751382/3a1dca6d-7467-43e8-9992-e79a41fa3858.png align="center")

Let's get an overview of the architecture of Kubernetes and discover how it can offer us such remarkable features. From this point forward, we will refer to Kubernetes as k8s, a widely used abbreviation, since there are 8 letters between the 'k' and 's' in the word Kubernetes.

k8s works on the client-server architecture and it has two top-level components which are the control plane and worker nodes. The control plane and worker node are just machines running different components.

* **Control plane:** It is the most important part of k8s, this is the component responsible for managing the containers in the worker node.
    
* **Worker nodes:** These are machines that run the actual application in containers.
    
* **kubectl:** The kubectl is a command-line tool that enables us to interact with the control plane. It allows us to issue commands and provide a configuration file specifying how we want our cluster to be configured.
    

The control plane and the worker node, when combined, are referred to as a k8s cluster.

## ‚úîÔ∏è Components of a k8s cluster.‚öôÔ∏è

### üî∏ control plane üéõÔ∏è

The control plane contains all the components necessary for managing worker nodes. These components include the controller, controller manager, scheduler, API server, and etcd, which is a separate service that plays a vital role in the control plane.

Let's explore all the components one by one:

1. **controller:**
    
    * controllers are control loops that monitor the state of your cluster by connecting to the API server. In robotics, a control loop is a non-terminating loop that regulates the state of the system.
        
    * controllers watch for changes to the desired state as defined in the API objects and make the necessary changes to the cluster to align the actual state with the desired state.
        
    * different types of controllers monitor the different aspects of the state of the cluster.
        
2. **controller manager:**
    
    * The controller manager is a daemon that embeds the core controllers shipped with k8s.
        
    * the controller manager watches for new events from the API server and handles them using the controllers that are built into it. This ensures that the cluster remains in the desired state at all times.
        
    * Each controller functions as an independent process, but to reduce complexity they are combined into a binary and executed as a single process.
        
        There are two different types of controller managers:
        
        * **kube-controller-manager:**
            
            It is the daemon that runs controllers which are components of k8s control plane. It consists of a set of controllers that watch for changes to the resources in the cluster and take action to move the current cluster state towards the desired state. In short, it is the process that runs the core k8s controllers.
            
            Different types of controllers that come under kube-controller-manager are node controller, replication controller, endpoint controller, service account & token controller, volume controller and many more.
            
        * **cloud-controller-manager:**
            
            The standard kube-controller-manager solely comprises controllers responsible for managing k8s resources, with no knowledge of the underlying cloud infrastructure.
            
            The cloud-controller-manager enhances the functionality of the standard kube-controller-manager by integrating it with a cloud provider.
            
            It runs cloud-specific controllers and lets you link your cluster to your cloud provider's API.
            
            Different types of controllers that come under cloud-controller-manager are load balancer controllers, ingress controller, Route53 controller, auto-scaling group controllers, elastic-network interface controllers and many more.
            
3. **etcd:**
    
    It is an open-source, distributed, consistent key-value store for shared configuration, service discovery, and scheduler coordination of distributed systems or clusters of machines.
    
    It can be considered a database or storage system that maintains the state and metadata of the entire cluster in a key-value format. It is consistent and highly available and works as a central point of reference for the cluster's state.
    
    It has the following features:
    
    * *fully replicated:* The entire state is available on every node in the cluster.
        
    * *secure:* For security purposes, it implements automatic TLS and offers optional client certificate authentication.
        
    * *fast:* It can perform up to 10,000 writes per second.
        
4. **scheduler:**
    
    * This component is responsible for the creation and management of pods on the nodes.
        
    * It gets the hardware information about the nodes from the etcd and creates pods on the nodes accordingly.
        
    * The scheduler consistently creates pods within the nodes, ensuring that the resources of all nodes are utilized effectively unless instructed to do otherwise.
        
5. **API server:**
    
    * All the components mentioned above do not communicate with each other directly; instead, they interact with the API server to carry out their tasks.
        
    * When we, as users, want to make changes to the cluster, we must interact with the API server to facilitate these changes. We can also provide the desired configuration of our cluster in the form of a YAML file(usually known as manifest files) to the API server, which will then connect with the necessary components to implement the changes accordingly.
        
    * The API server can also scale itself automatically according to the load increases or decreases.
        

### üî∏ worker node üë∑‚Äç‚ôÇÔ∏èüñ•Ô∏è

The worker node has components that communicate with the control plane and create pods and containers to run our application.

1. **kubelet:**
    
    * This is an agent that runs on every worker node in the cluster and its main responsibility is to communicate with the API server to get the pod information and specification and then take necessary actions to ensure that the pods are running.
        
    * It is responsible for many tasks like pulling images, creating and managing containers, restarting containers after they have crashed, monitoring container resource usage, reporting the status of the pods to the API server etc.
        
    * It connects with the container runtime through the container runtime interface (CRI) to manage the actual containers. It uses the CRI to start, stop and monitor containers.
        
2. **kube-proxy:**
    
    kube-proxy is a network proxy that runs on each node in the k8s cluster. It is responsible for assigning IP addresses to the pods. It maintains network rules on the host and performs the following networking functions:
    
    * *service discovery:*
        
        It maintains network rules that allow Services to work. A Service is an abstraction that allows Pods to be accessed consistently, regardless of which node they are scheduled on.
        
        When a request is made to a Service's IP address, kube-proxy reroutes the request to one of the Pods implementing that Service. This redirection is accomplished using network address translation (NAT) rules maintained by kube-proxy.
        
        This enables Pods to be accessed through a stable Service IP/hostname, even if the actual Pods supporting that Service change (due to rescheduling or replacement). Kube-proxy facilitates this by redirecting Service requests to the corresponding Pods.
        
    * *network programming:*
        
        kube-proxy also programs network rules on the host node to allow network access from pods to Services. It handles the network programming for Service Types: ClusterIP, NodePort and LoadBalancer.
        
    * *health checking:*
        
        for LoadBalancer type Services, kube-proxy performs health checking on the backend Pods to enable fast failover in case a Pod dies.
        
    * *Loose coupling:*
        
        kube-proxy is loosely coupled with the k8s control plane. This means it can still function even if the API server is temporarily unavailable.
        
3. **pod:**
    
    * A pod is the smallest control unit in k8s, it represents one or a group of containers deployed on the same host.
        
    * Usually, it is advised to have only one container within a pod. If more than one container is used within a pod, they must be tightly coupled, which can lead to issues during their operation.
        
    * The controllers manage only the pods, not the container, this is done by the container runtime.
        
    * In a worker node, we cannot start a container without starting a pod.
        
    * A pod is created by using the pod spec file which has a description of which container it should run, what volumes it has, and what type of network configuration it will follow.
        
4. **container runtime:**
    
    This is the component that does the actual work of creating and maintaining containers and pulling the images etc., the kubelet communicates with the container runtime through the Container Runtime Interface to make it all happen.
    

### üî∏ kubectl üë®‚Äçüíª

It is a command line tool for communicating with a k8s cluster's control plane, using its API. kubectl connects with the API server in the control plane to get things done.

We can perform the following tasks using kubectl:

* Run commands against k8s clusters
    
* View cluster state
    
* Create, delete and update components of the cluster (e.g. pods, services, deployments)
    
* View logs of various objects
    
* Execute commands on containers
    

## üìç Conclusion.üëã

Oh my goodness, today we've dived into the incredible world of Kubernetes! ü§© Make sure to explore it yourself, because it's such a vast and exciting topic - it'll take some time to get fully familiarized with it. But don't worry, in our upcoming blogs, we'll be discovering the amazing Minikube, a fantastic tool for working with Kubernetes locally! Get ready for an awesome learning journey! üöÄüéâ

Check out [this blog](https://yashraj-jaiswal.hashnode.dev/easy-to-follow-k8s-cluster-setup-and-minikube-installation-guide-for-local-environments) where we are setting up k8s cluster using kubeadm and also a fast-track method using minikube.